{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Spam_text_classification.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVWE4SIjT_H8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import nltk\n",
        "import sklearn\n",
        "import pandas\n",
        "import numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5tzNeA7T_ID",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "de8cc0a3-f441-4dbc-8a6f-3c0efe97f807"
      },
      "source": [
        "print(\"Python: {}\".format(sys.version))\n",
        "print(\"NLTK: {}\".format(nltk.__version__))\n",
        "print(\"Sklearn: {}\".format(sklearn.__version__))\n",
        "print(\"pandas: {}\".format(pandas.__version__))\n",
        "print(\"numpy: {}\".format(numpy.__version__))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python: 3.6.9 (default, Nov  7 2019, 10:44:02) \n",
            "[GCC 8.3.0]\n",
            "NLTK: 3.2.5\n",
            "Sklearn: 0.22.1\n",
            "pandas: 0.25.3\n",
            "numpy: 1.17.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99QojzXxT_IH",
        "colab_type": "text"
      },
      "source": [
        "## 1. Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nftkdve4T_IJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# load the sms\n",
        "df = pd.read_table('SMSSpamCollection', header=None, encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEG_7t-FT_IO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "3d150049-81f1-4e1e-dd05-6ea888a06b3d"
      },
      "source": [
        "# print useful data\n",
        "print(df.info())\n",
        "print(df.head())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            "0    5572 non-null object\n",
            "1    5572 non-null object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n",
            "None\n",
            "      0                                                  1\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMsskEd4T_IU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e50db2b7-a369-47fc-e651-5d6c562dd907"
      },
      "source": [
        "# check the class distribution\n",
        "classes = df[0]\n",
        "print(classes.value_counts())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ham     4825\n",
            "spam     747\n",
            "Name: 0, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5IDz92UT_IY",
        "colab_type": "text"
      },
      "source": [
        "## 2. Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8PAYV4TT_IZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "43773f49-15e6-4948-d71b-570b99f615a7"
      },
      "source": [
        "# convert class labels to binary values 0=ham, 1=spam\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "Y = encoder.fit_transform(classes)\n",
        "\n",
        "print(classes[:10])\n",
        "print(Y[:10])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0     ham\n",
            "1     ham\n",
            "2    spam\n",
            "3     ham\n",
            "4     ham\n",
            "5    spam\n",
            "6     ham\n",
            "7     ham\n",
            "8    spam\n",
            "9    spam\n",
            "Name: 0, dtype: object\n",
            "[0 0 1 0 0 1 0 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2buoGbwT_Ie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "60cd809a-1a1c-4e93-a070-e4094d5c1c83"
      },
      "source": [
        "#store the sms message data\n",
        "text_messages = df[1]\n",
        "print(text_messages[:10])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    Go until jurong point, crazy.. Available only ...\n",
            "1                        Ok lar... Joking wif u oni...\n",
            "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3    U dun say so early hor... U c already then say...\n",
            "4    Nah I don't think he goes to usf, he lives aro...\n",
            "5    FreeMsg Hey there darling it's been 3 week's n...\n",
            "6    Even my brother is not like to speak with me. ...\n",
            "7    As per your request 'Melle Melle (Oru Minnamin...\n",
            "8    WINNER!! As a valued network customer you have...\n",
            "9    Had your mobile 11 months or more? U R entitle...\n",
            "Name: 1, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGoN4PWvT_Ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use regular expression to replace email, urls,\n",
        "\n",
        "# replace email address with 'emailaddr'\n",
        "processed = text_messages.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$', 'emailaddr')\n",
        "\n",
        "# replace urls with 'webaddress'\n",
        "processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}{/\\S*}?$', 'webaddress')\n",
        "\n",
        "# replace money symbols with 'moneysymb'\n",
        "processed = processed.str.replace(r'ï¿½|\\$','moneysymb')\n",
        "\n",
        "# replcae 10 digit phone numbers with 'phone number'\n",
        "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$', 'phonenumber')\n",
        "\n",
        "# replace normal numbers with numbr\n",
        "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnhXjBtwT_Io",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# replace punc\n",
        "processed = processed.str.replace(r'[\\n\\d\\s]', ' ')\n",
        "\n",
        "#replace whitespace\n",
        "processed = processed.str.replace(r'\\s+', ' ')\n",
        "\n",
        "# remove leading and trailing whitespace\n",
        "processed = processed.str.replace(r'^\\s+|\\s+?$', '')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bH7pZvuT_It",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "199742d1-4f23-473b-979a-d18626a38d67"
      },
      "source": [
        "# changing the words to lowercase\n",
        "processed = processed.str.lower()\n",
        "print(processed[:10])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    go until jurong point, crazy.. available only ...\n",
            "1                        ok lar... joking wif u oni...\n",
            "2    free entry in numbr a wkly comp to win fa cup ...\n",
            "3    u dun say so early hor... u c already then say...\n",
            "4    nah i don't think he goes to usf, he lives aro...\n",
            "5    freemsg hey there darling it's been numbr week...\n",
            "6    even my brother is not like to speak with me. ...\n",
            "7    as per your request 'melle melle (oru minnamin...\n",
            "8    winner!! as a valued network customer you have...\n",
            "9    had your mobile numbr months or more? u r enti...\n",
            "Name: 1, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6lkGX3oUS2k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "57e4563c-aa93-41f2-ff9c-5c21ad9c05ae"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVoH4RUUT_Ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove stop words\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "processed = processed.apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv7fcJIoT_I1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove word stems using a Porter stemmer\n",
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "processed = processed.apply(lambda x: ' '.join(ps.stem(term) for term in x.split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3CNRpCeT_I5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# creating a bag-of-words\n",
        "all_words = []\n",
        "\n",
        "for message in processed:\n",
        "    words = word_tokenize(message)\n",
        "    for w in words:\n",
        "        all_words.append(w)\n",
        "        \n",
        "all_words = nltk.FreqDist(all_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmiPSo6dT_I9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "742eba8c-8604-4c2b-c1bb-eb148cdf1a3f"
      },
      "source": [
        "# print total no of words and print most common\n",
        "print(\"Number of words:: {}\".format(len(all_words)))\n",
        "print(\"Most common words:: {}\".format(all_words.most_common(15)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words:: 8525\n",
            "Most common words:: [('.', 4944), ('numbr', 2280), (',', 1979), ('?', 1550), ('!', 1397), ('...', 1261), ('u', 1111), ('&', 922), (';', 768), (':', 744), ('call', 644), ('i', 626), (')', 499), ('get', 445), ('go', 443)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-RhR_udT_JC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use the first 1500 most common words as features\n",
        "word_features = list(all_words.keys())[:1500]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlaTN0rzT_JG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "9b063e32-ab3a-41ba-9765-b571e1e357c4"
      },
      "source": [
        "# define find_features function\n",
        "def find_features(message):\n",
        "    words = word_tokenize(message)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features[word] = (word in words)\n",
        "        \n",
        "    return features\n",
        "\n",
        "features = find_features(processed[0])\n",
        "for key, value in features.items():\n",
        "    if value == True:\n",
        "        print(key)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "go\n",
            "jurong\n",
            "point\n",
            ",\n",
            "crazy..\n",
            "avail\n",
            "bugi\n",
            "n\n",
            "great\n",
            "world\n",
            "la\n",
            "e\n",
            "buffet\n",
            "...\n",
            "cine\n",
            "got\n",
            "amor\n",
            "wat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMYZ-8YAT_JJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find features for all messages\n",
        "messages = zip(processed, Y)\n",
        "\n",
        "# define a seed for reproducability\n",
        "seed = 1\n",
        "np.random.seed = seed\n",
        "#np.random.shuffle(messages)\n",
        "\n",
        "# call find_features for each sms messages\n",
        "featuresets = [(find_features(text), label) for (text, label) in messages]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_u3-JnjT_JM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split training and testing data sets using sklearn\n",
        "from sklearn import model_selection\n",
        "\n",
        "training, testing = model_selection.train_test_split(featuresets, test_size=0.25, random_state= seed)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKsj96HiT_JS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1fc3442d-3307-400b-8bba-76dce5b02ae5"
      },
      "source": [
        "print('Training {}'.format(len(training)))\n",
        "print('Testing {}'.format(len(testing)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training 4179\n",
            "Testing 1393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8_M8g0fT_JX",
        "colab_type": "text"
      },
      "source": [
        "## 3. Scikit-Learn Classifiers with NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpTjkoLST_JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgyLsRxGT_Jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the model to train\n",
        "names = ['K Nearest Neighbors', 'Decision Tree',\n",
        "        'Random Forest', 'Logistic Regression',\n",
        "        'SGD Classifier', 'Naive Bayes', \n",
        "        'SVN Linear']\n",
        "\n",
        "classifier = [\n",
        "    KNeighborsClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    LogisticRegression(),\n",
        "    SGDClassifier(max_iter=100),\n",
        "    MultinomialNB(),\n",
        "    SVC(kernel='linear')\n",
        "]\n",
        "models = zip(names, classifier)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu6_WRTOT_Jh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "c69143bc-33ff-4946-bdcb-d490a276ccad"
      },
      "source": [
        "list(models)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('K Nearest Neighbors',\n",
              "  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                       metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                       weights='uniform')),\n",
              " ('Decision Tree',\n",
              "  DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                         max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                         min_samples_leaf=1, min_samples_split=2,\n",
              "                         min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                         random_state=None, splitter='best')),\n",
              " ('Random Forest',\n",
              "  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                         criterion='gini', max_depth=None, max_features='auto',\n",
              "                         max_leaf_nodes=None, max_samples=None,\n",
              "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                         min_samples_leaf=1, min_samples_split=2,\n",
              "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                         n_jobs=None, oob_score=False, random_state=None,\n",
              "                         verbose=0, warm_start=False)),\n",
              " ('Logistic Regression',\n",
              "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                     intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                     multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                     random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                     warm_start=False)),\n",
              " ('SGD Classifier',\n",
              "  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "                early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "                l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
              "                max_iter=100, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
              "                power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
              "                validation_fraction=0.1, verbose=0, warm_start=False)),\n",
              " ('Naive Bayes', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)),\n",
              " ('SVN Linear',\n",
              "  SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "      decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "      max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "      tol=0.001, verbose=False))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHUtyvD5T_Jl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "324f764a-93c0-4bb8-ed78-6f43c5b79be1"
      },
      "source": [
        "# wrap models in NLTK\n",
        "from nltk.classify.scikitlearn import SklearnClassifier\n",
        "\n",
        "for (name, model) in zip(names, classifier):\n",
        "    nltk_model = SklearnClassifier(model)\n",
        "    nltk_model.train(training)\n",
        "    accuracy = nltk.classify.accuracy(nltk_model, testing) * 100\n",
        "    print('{}: Accuracy: {}'.format(name, accuracy))\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K Nearest Neighbors: Accuracy: 93.25197415649676\n",
            "Decision Tree: Accuracy: 97.4156496769562\n",
            "Random Forest: Accuracy: 98.63603732950466\n",
            "Logistic Regression: Accuracy: 98.63603732950466\n",
            "SGD Classifier: Accuracy: 98.27709978463747\n",
            "Naive Bayes: Accuracy: 98.42067480258436\n",
            "SVN Linear: Accuracy: 98.56424982053123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCoxARjQT_Jp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ensemble method - Voting Classifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "models = zip(names, classifier)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IxOCjtgT_Jr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a268ae25-0315-48e4-d940-b31b77f2e058"
      },
      "source": [
        "nltk_ensamble = SklearnClassifier(VotingClassifier(estimators=list(zip(names, classifier)), voting='hard', n_jobs=-1))\n",
        "nltk_ensamble.train(training)\n",
        "accuracy = nltk.classify.accuracy(nltk_ensamble, testing) * 100\n",
        "print(\"Ensemble Method Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ensemble Method Accuracy: 98.56424982053123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHG7IzxBT_Jy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}